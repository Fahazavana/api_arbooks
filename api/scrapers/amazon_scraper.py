import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from .BaseScraper import BaseScraper
from api.bd_scraping_arbook.models_scraping import Product_scraping
from .utils import Product
import os 
logging.basicConfig(level=os.environ.get("LOGLEVEL"))


async def save_to_mongo(db_manager, products: list[dict]):
    """Ins√®re les produits scrapp√©s dans MongoDB en √©vitant les doublons (mise √† jour si d√©j√† existant)."""

    if not db_manager.is_initialized():  #  V√©rifie l'initialisation
        success = await db_manager.initialize()
        if not success:
            logging.error(
                "√âchec de l'initialisation de la base de donn√©es. Annulation de l'insertion."
            )
            return

    if not products:
        logging.info("Aucun produit √† enregistrer dans MongoDB.")
        return

    for item in products:
        try:
            # V√©rifier si le produit existe d√©j√†
            existing_product = await Product_scraping.find_one(
                {"product_id": item["product_id"]}
            )

            if existing_product:
                await existing_product.set(item)  #  Mise √† jour
                logging.info(
                    f"Produit {item['name']} ({item['product_id']}) mis √† jour avec succ√®s !"
                )
            else:
                new_product = Product_scraping(**item)
                await new_product.insert()  #  Insertion
                logging.info(
                    f"Produit {item['name']} ({item['product_id']}) ins√©r√© avec succ√®s !"
                )

        except Exception as e:
            logging.error(
                f"Erreur lors de l'insertion du produit {item.get('product_id', 'inconnu')}: {e}"
            )


class AmazonScraper(BaseScraper):

    BASE_URL = "https://www.amazon.fr"
    SEARCH_URL = "https://www.amazon.fr/s"
    # Headers that mimic a real browser
    HEADERS = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
        "Accept-Language": "fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "none",
        "Sec-Fetch-User": "?1",
        "Cache-Control": "max-age=0",
        "rtt": "50",
        "downlink": "10",
        "ect": "4g",
    }

    def __init__(self, db_manager):
        self.db_manager = db_manager
        """Initialisation du navigateur avec les options."""
        options = Options()
        options.add_argument(
            "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
        )
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--headless")  # Set to False to see the browser
        options.add_argument("--disable-popup-blocking")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-infobars")
        options.add_argument("--disable-gpu")
        options.add_argument("--start-maximized")
        options.add_argument("--log-level=3")  # Reduce unnecessary logs

        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=options)

    async def __aenter__(self):
        return self

    async def __aexit__(self, *excinfo):
        self.driver.quit()

    async def get_page_content(self, url: str, wait_for: str) -> str:
        """R√©cup√©rer le contenu de la page avec Selenium et gestion des erreurs."""
        try:
            self.driver.get(url)
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, wait_for))
            )
            return self.driver.page_source
        except Exception as e:
            logging.error(
                f"Erreur lors du chargement de la page {url} : {str(e)}"
            )  # More specific error message
            return ""

    async def search(self, query: str, limit: int = 100) -> List[Dict[str, Any]]:
        products = []
        params = {
            "k": query,
            "ref": "nb_sb_noss",
            "sprefix": f"{query},aps,283",
            "crid": "2M7LQQC1YQLR0",
        }
        try:
            logging.info(f" Recherche de '{query}' sur Amazon!")
            content = await self.get_page_content(
                f"{self.SEARCH_URL}?{self._encode_params(params)}",
                'div[data-component-type="s-search-result"]',
            )
            if not content:
                return products

            soup = BeautifulSoup(content, "lxml")
            items = soup.select('div[data-component-type="s-search-result"]')
            logging.info(f"Trouv√© {len(items)} √©l√©ments sur Amazon pour: {query}")

            for item in items[:limit]:
                product = self.parse_item(item)
                if product:
                    products.append(product)

            if products:
                logging.info(" Enregistrement des produits dans MongoDB...")
                await save_to_mongo(self.db_manager, products)

        except Exception as e:
            logging.error(f"Erreur lors du scraping d'Amazon: {str(e)}")
            raise
        return products

    def parse_item(self, item) -> Optional[Dict[str, Any]]:
        product = Product(source="amazon")
        try:
            # Get product id
            asin = item.get("data-asin", "")
            product.product_id = asin if asin else None

            # Titre
            product.name = item.h2.text.strip() if item.h2 else ""

            livraison = item.select_one('div[data-cy="delivery-recipe"]')
            livraison = livraison.text if livraison else None
            product.delivery_price = (
                "".join(livraison.strip().split(" ")[2:]) if livraison else None
            )

            # URL du produit
            href = item.select_one("a.a-link-normal").get("href", "")
            product.url = (
                self.BASE_URL + href if href and not href.startswith("http") else href
            )
            # URL de l'image
            product.main_photo = (
                item.select_one("img.s-image")["src"]
                if item.select_one("img.s-image")
                else None
            )
            # Prix
            product.price = (
                item.find("span", class_="a-offscreen").text.strip()
                if item.find("span", class_="a-offscreen")
                else None
            )
            # √âvaluation du produit
            product.rating = (
                item.select_one("span.a-icon-alt").text.strip()
                if item.select_one("span.a-icon-alt")
                else None
            )
            # Exclusivit√© Amazon
            product.is_exclusive = bool(
                item.select_one("span.a-badge-text")
                and "Exclusivit√© Amazon" in item.select_one("span.a-badge-text").text
            )

            # Disponibilit√© en stock
            product.stock = not bool(item.select_one(".s-item__out-of-stock"))

            if product.is_valid():
                logging.info(product)
                return product.to_dict()

        except Exception as e:
            logging.error(f"Erreur lors de l'extraction d'un produit : {str(e)}")
            return None

    def parse_table(self, table):
        headers = [el.text.strip() for el in table.find_all("th")]
        rows = [el.text.strip() for el in table.find_all("td")]
        return {th: td for th, td in zip(headers, rows)}

    def parse_details(self, soup):
        product = Product(source="amazon")
        try:
            # R√©cup√©rer l'URL canonique du produit
            canonical_link = soup.select_one('link[rel="canonical"]')
            product.url = canonical_link.get("href") if canonical_link else None

            #  Extraction de l'ASIN (ID du produit)
            product.product_id = None

            #  M√©thode principale : `#all-offers-display-params`
            asin_element = soup.select_one("#all-offers-display-params")
            if asin_element:
                product.product_id = asin_element.get("data-asin")

            #  M√©thode alternative : `input[name="ASIN"]`
            if not product.product_id:
                asin_input = soup.select_one('input[name="ASIN"]')
                if asin_input:
                    product.product_id = asin_input.get("value")

            #  V√©rification finale
            if not product.product_id:
                logging.warning(
                    f" Impossible de r√©cup√©rer l'ID du produit pour {product.url}."
                )

            # R√©cup√©rer le prix du produit
            price_element = soup.select_one(
                'div[id*="corePrice"] .a-offscreen, div[id*="corePrice"] .aok-offscreen'
            )
            product.price = price_element.text.strip() if price_element else None

            # Cat√©gories
            category_elements = soup.select("#wayfinding-breadcrumbs_feature_div a")
            product.categories = (
                [cat.text.strip() for cat in category_elements]
                if category_elements
                else None
            )

            # Nom du produit
            title_element = soup.select_one("#productTitle")
            product.name = title_element.text.strip() if title_element else None

            # Photos d√©taill√©es
            image_elements = soup.select("#main-image-container img") + soup.select(
                "#altImages img"
            )
            product.detailed_photos = (
                [img.get("src") for img in image_elements if img.get("src")]
                if image_elements
                else None
            )

            # Table des caract√©ristiques
            product_table = soup.select_one(
                "#productDetails_feature_div table"
            ) or soup.select_one("#prodDetails table")
            product.feature_table = (
                self.parse_table(product_table) if product_table else None
            )

            # Couleurs disponibles
            color_elements = soup.select("#variation_color_name ul img")

            # Extraire uniquement le nom des couleurs (List[str])
            product.colors = (
                [
                    color.get("alt", "").strip()
                    for color in color_elements
                    if color.get("alt")
                ]
                if color_elements
                else None
            )

            # Si tu veux stocker aussi les images, utilise un autre champ `colors_images`
            product.colors_images = (
                {
                    color.get("alt", "").strip(): color.get("src", "")
                    for color in color_elements
                    if color.get("alt")
                }
                if color_elements
                else None
            )

            # Description du produit
            description_element = soup.select_one("#productDescription p")
            product.description = (
                description_element.text.strip() if description_element else None
            )

            return [product.to_dict()]

        except Exception as e:
            logging.error(f" Erreur extraction d√©tail article Amazon : {str(e)}")
            return []

    # async def get_detail(self, product_url) -> List[Dict[str, Any]]:
    #     content = await self.get_page_content(product_url, "#navFooter")
    #     await self.__aexit__()
    #     if not content:
    #         return []
    #     soup = BeautifulSoup(content, "lxml")
    #     return self.parse_details(soup)

    async def get_detail(self, product_url: str) -> List[Dict[str, Any]]:
        """R√©cup√®re et met √† jour les d√©tails d'un produit Amazon."""

        logging.info(f" R√©cup√©ration du produit : {product_url}")
        content = await self.get_page_content(product_url, "#navFooter")

        if not content:
            logging.warning(f" Aucun contenu r√©cup√©r√© pour {product_url}.")
            return []

        soup = BeautifulSoup(content, "lxml")
        details = self.parse_details(soup)

        if not details:
            logging.warning(
                f" Impossible d'extraire les d√©tails du produit {product_url}."
            )
            return []

        logging.info(f" D√©tails extraits : {details}")

        #  Correction : Utilisation de update_product_details()
        updated_details = await self.update_product_details(details[0])

        return [updated_details]  # Toujours retourner une liste

    async def update_product_details(
        self, detailed_product: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Met √† jour MongoDB avec les nouvelles donn√©es du produit Amazon."""
        try:
            if not isinstance(detailed_product, dict):
                logging.error(
                    f" Erreur: `detailed_product` n'est pas un dictionnaire ! Type re√ßu : {type(detailed_product)}"
                )
                return {}

            product_id = detailed_product.get("product_id")
            if not product_id:
                logging.warning(" Impossible de r√©cup√©rer l'ID du produit.")
                return {}

            #  V√©rifier que MongoDB est bien initialis√©
            if not self.db_manager.is_initialized():
                logging.info("üõ†Ô∏è Initialisation de MongoDB avec Beanie...")
                await self.db_manager.initialize()

            #  Correction : Convertir `uploaded` en `str` si c'est un `dict`
            if "uploaded" in detailed_product and isinstance(
                detailed_product["uploaded"], dict
            ):
                uploaded_data = detailed_product["uploaded"]
                detailed_product["uploaded"] = (
                    f"{uploaded_data.get('scraped', 'N/A')} - {uploaded_data.get('time', 'N/A')}"
                )

            #  Rechercher si le produit existe d√©j√† en base
            existing_product = await Product_scraping.find_one(
                {"product_id": product_id}
            )

            if existing_product:
                updated_fields = {
                    k: v
                    for k, v in detailed_product.items()
                    if getattr(existing_product, k, None) != v and v is not None
                }

                if updated_fields:
                    try:
                        await existing_product.set(updated_fields)
                        logging.info(
                            f" Produit {product_id} mis √† jour avec {len(updated_fields)} nouvelles valeurs."
                        )
                    except Exception as e:
                        logging.error(
                            f" Erreur lors de la mise √† jour du produit `{product_id}` dans MongoDB : {e}"
                        )
                else:
                    logging.info(f"‚ÑπÔ∏è Aucun changement d√©tect√© pour {product_id}.")
            else:
                try:
                    new_product = Product_scraping(**detailed_product)
                    await new_product.insert()
                    logging.info(f"üÜï Produit {product_id} ajout√© en base.")
                except Exception as e:
                    logging.error(
                        f" Erreur lors de l'insertion du produit `{product_id}` dans MongoDB : {e}"
                    )

            return detailed_product

        except Exception as e:
            logging.error(
                f" Erreur inattendue lors de la mise √† jour du produit `{product_id}` : {e}"
            )
            return {}
